{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkJu3K5k8tWk"
   },
   "source": [
    "# TAMYETE JUSTICE NTOR - INFORMATION RETRIVAL COURSE WORK\n",
    "\n",
    "#  Postgraduate Research Search Engine\n",
    "In this notebook we'll go through all code for building our own search engine specialised on finding potential supervisors for postgraduate research student\n",
    "Each search engine consists of three main components:\n",
    "\n",
    "\n",
    "* Crawler\n",
    "* Indexer\n",
    "* Query processor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WG-1-CN_mLTu"
   },
   "source": [
    "## A. Crawler\n",
    "We start with building crawler using Beautiful Soap that, extracts lecturers name, Research Area and Link to personal profile from three Universities in the United Kingdom(University of Hull, Kingston University and Swansea University) Processes this information, put in a pandas dataframe and stores it as csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfRHdlHTmLTx"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "JKMcZm97mLTy",
    "outputId": "f1e76362-0c88-4092-d6ec-b3b530ba3b34"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University of Hull Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JGjcps0s2rc4",
    "outputId": "808313a1-ceb9-4937-9c6b-1ec124b606ef"
   },
   "outputs": [],
   "source": [
    "stafflink1=[]\n",
    "names1 = []\n",
    "area1= []\n",
    "links1= []\n",
    "department = []\n",
    "page1 = requests.get(\"https://www.hull.ac.uk/work-with-us/research/our-people\")\n",
    "soup1 = BeautifulSoup(page1.text, 'html.parser')\n",
    "for main in soup1.find_all('li', class_='item'):\n",
    "    try:\n",
    "        slist = main.a['href']\n",
    "    except Exception as e:\n",
    "        slist = 'None'\n",
    "    stafflink1.append(slist)\n",
    "for ppage in stafflink1:\n",
    "    ppages = requests.get(\"https://www.hull.ac.uk\" + str(ppage))\n",
    "    sp1 = BeautifulSoup(ppages.text, 'html.parser')\n",
    "    try:\n",
    "        sname= sp1.find('section', class_='profile').h1.text \n",
    "    except Exception as e:\n",
    "        sname = 'None'\n",
    "    names1.append(sname)    \n",
    "    try:\n",
    "        sarea= sp1.find('div', id='research-panel').text\n",
    "    except Exception as e:\n",
    "        sarea = 'None'\n",
    "    area1.append(sarea)\n",
    "    \n",
    "    slink = (\"https://www.hull.ac.uk\" + str(ppage))\n",
    "    links1.append(slink)\n",
    "    try:\n",
    "        dep= sp1.find('div', class_='faculty').li.text\n",
    "    except Exception as e:\n",
    "        dep = 'None'\n",
    "    department.append(dep)\n",
    "hull = pd.DataFrame({\n",
    "'name': names1,\n",
    "'link':links1,\n",
    "'research_interest': area1\n",
    "})  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kingston University Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stafflink2=[]\n",
    "names2 = []\n",
    "area2 = []\n",
    "links2= []\n",
    "page2 = requests.get(\"https://www.kingston.ac.uk/staff/search-results/faculty/faculty-of-science-engineering-and-computing-5\")\n",
    "soup2 = BeautifulSoup(page2.text, 'html.parser')\n",
    "for main2 in soup2.find_all('div', class_='staff-profile-listing-img'):\n",
    "    try:\n",
    "        slist2 = main2.a['href']\n",
    "    except Exception as e:\n",
    "        slist2 = 'None'\n",
    "    stafflink2.append(slist2)\n",
    "for ppage2 in stafflink2:\n",
    "    ppages2 = requests.get(\"https://www.kingston.ac.uk\" + str(ppage2))\n",
    "    sp2 = BeautifulSoup(ppages2.text, 'html.parser')\n",
    "    try:\n",
    "        sname2=sp2.find('h1', id ='staff-profile-h1').text \n",
    "    except Exception as e:\n",
    "        sname2 = 'None'\n",
    "    names2.append(sname2)    \n",
    "    try:\n",
    "        sarea2=sp2.find('div', class_='single-col-accordian-inner').find_all('div', class_='site-expand-box-content')[1].text\n",
    "    except Exception as e:\n",
    "        sarea2 = 'None'\n",
    "    area2.append(sarea2)\n",
    "    \n",
    "    slink2 = (\"https://www.kingston.ac.uk\" + str(ppage2))\n",
    "    links2.append(slink2)    \n",
    "kingston = pd.DataFrame({\n",
    "'name': names2,\n",
    "'link':links2,\n",
    "'research_interest': area2\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swansea University "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stafflinks3=[]\n",
    "stafflink3=[]\n",
    "names3 = []\n",
    "area3 = []\n",
    "links3= []\n",
    "stype = ['professors-contents','associate-professors-contents','senior-lecturers-contents','lecturers-contents']\n",
    "page3 = requests.get(\"https://www.swansea.ac.uk/staff/engineering/\")\n",
    "soup3 = BeautifulSoup(page3.text, 'html.parser')\n",
    "for sstype in stype:\n",
    "    for main3 in soup3.find('div', id =str(sstype)).find_all('p'):\n",
    "        try:\n",
    "            slist3 = main3.a['href']\n",
    "        except Exception as e:\n",
    "            slist3= None\n",
    "        stafflinks3.append(slist3)\n",
    "        stafflink3 = list(filter(None,stafflinks3)) \n",
    "def Filter(stafflinks3, substr): \n",
    "    return [str for str in stafflinks3 if\n",
    "             any(sub in str for sub in substr)]\n",
    "substr =['http']\n",
    "stafflink3 = Filter(stafflinks3, substr)\n",
    "for ppage3 in stafflink3:\n",
    "    ppages3 = requests.get(str(ppage3))\n",
    "    sp3 = BeautifulSoup(ppages3.text, 'html.parser')\n",
    "    try:\n",
    "        sname3=sp3.find('h1', class_='staff-profile-overview-honorific-prefix-and-full-name').text\n",
    "    except Exception as e:\n",
    "        sname3 = 'None'\n",
    "    names3.append(sname3)    \n",
    "    try:\n",
    "        sarea3= sp3.find('div', class_='staff-profile-areas-of-expertise').text\n",
    "    except Exception as e:\n",
    "        sarea3 = 'None'\n",
    "    area3.append(sarea3)    \n",
    "    slink3 = (str(ppage3))\n",
    "    links3.append(slink3)\n",
    "swansea = pd.DataFrame({\n",
    "'name': names3,\n",
    "'link':links3,\n",
    "'research_interest': area3\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the results and saving the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni =[hull,kingston,swansea]\n",
    "university = pd.concat(uni)\n",
    "university['ID'] = [x for x in range(1, len(university.values)+1)]\n",
    "university.to_csv('university.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>research_interest</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Amy Tomlinson</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/amy-tom...</td>\n",
       "      <td>\\n\\nResearch interests\\nSport rehabilitation \\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr Ireneous Soyiri</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/ireneou...</td>\n",
       "      <td>\\n\\nResearch interests\\nMy areas of interests ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher Clarke</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/christo...</td>\n",
       "      <td>\\n\\nPostgraduate supervision\\nDr Clarke would ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roberto Fernandez Arrieta</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/roberto...</td>\n",
       "      <td>\\n\\nResearch interests\\nGeomorphology \\nSedime...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miss Katherine Bloomfield</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/katheri...</td>\n",
       "      <td>\\n\\nResearch interests\\nPublic sector procurem...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name  \\\n",
       "0          Miss Amy Tomlinson   \n",
       "1          Dr Ireneous Soyiri   \n",
       "2          Christopher Clarke   \n",
       "3   Roberto Fernandez Arrieta   \n",
       "4   Miss Katherine Bloomfield   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.hull.ac.uk/staff-directory/amy-tom...   \n",
       "1  https://www.hull.ac.uk/staff-directory/ireneou...   \n",
       "2  https://www.hull.ac.uk/staff-directory/christo...   \n",
       "3  https://www.hull.ac.uk/staff-directory/roberto...   \n",
       "4  https://www.hull.ac.uk/staff-directory/katheri...   \n",
       "\n",
       "                                   research_interest  ID  \n",
       "0  \\n\\nResearch interests\\nSport rehabilitation \\...   1  \n",
       "1  \\n\\nResearch interests\\nMy areas of interests ...   2  \n",
       "2  \\n\\nPostgraduate supervision\\nDr Clarke would ...   3  \n",
       "3  \\n\\nResearch interests\\nGeomorphology \\nSedime...   4  \n",
       "4  \\n\\nResearch interests\\nPublic sector procurem...   5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "university = pd.read_csv(\"university.csv\")\n",
    "university.drop(university.columns[0], axis=1, inplace=True)\n",
    "university.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 object\n",
      "link                 object\n",
      "research_interest    object\n",
      "ID                    int64\n",
      "dtype: object\n",
      "name                 0\n",
      "link                 0\n",
      "research_interest    0\n",
      "ID                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(university.dtypes)\n",
    "\n",
    "# to see where you're missing data and how much data is missing \n",
    "print(university.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "university.rename(columns={'name':'names'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>link</th>\n",
       "      <th>research_interest</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Amy Tomlinson</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/amy-tom...</td>\n",
       "      <td>\\n\\nResearch interests\\nSport rehabilitation \\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr Ireneous Soyiri</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/ireneou...</td>\n",
       "      <td>\\n\\nResearch interests\\nMy areas of interests ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher Clarke</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/christo...</td>\n",
       "      <td>\\n\\nPostgraduate supervision\\nDr Clarke would ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roberto Fernandez Arrieta</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/roberto...</td>\n",
       "      <td>\\n\\nResearch interests\\nGeomorphology \\nSedime...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miss Katherine Bloomfield</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/katheri...</td>\n",
       "      <td>\\n\\nResearch interests\\nPublic sector procurem...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Dr Min Luo</td>\n",
       "      <td>http://www.swansea.ac.uk/staff/engineering/min...</td>\n",
       "      <td>\\nAreas Of Expertise\\n\\nWave hydrodynamics\\nTw...</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Dr Christopher Phillips</td>\n",
       "      <td>https://www.swansea.ac.uk/staff/engineering/c....</td>\n",
       "      <td>None</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Dr Elizabeth Sackett</td>\n",
       "      <td>http://www.swansea.ac.uk/staff/engineering/e.s...</td>\n",
       "      <td>\\nAreas Of Expertise\\n\\nFatigue\\nCreep\\nStrain...</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Dr Andrew Tappenden</td>\n",
       "      <td>https://www.swansea.ac.uk/staff/engineering/a....</td>\n",
       "      <td>\\nAreas Of Expertise\\n\\nMechanical Design\\n3D ...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Dr Zhongfu Zhou</td>\n",
       "      <td>http://www.swansea.ac.uk/staff/engineering/z.z...</td>\n",
       "      <td>None</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          names  \\\n",
       "0            Miss Amy Tomlinson   \n",
       "1            Dr Ireneous Soyiri   \n",
       "2            Christopher Clarke   \n",
       "3     Roberto Fernandez Arrieta   \n",
       "4     Miss Katherine Bloomfield   \n",
       "..                          ...   \n",
       "992                  Dr Min Luo   \n",
       "993     Dr Christopher Phillips   \n",
       "994        Dr Elizabeth Sackett   \n",
       "995         Dr Andrew Tappenden   \n",
       "996             Dr Zhongfu Zhou   \n",
       "\n",
       "                                                  link  \\\n",
       "0    https://www.hull.ac.uk/staff-directory/amy-tom...   \n",
       "1    https://www.hull.ac.uk/staff-directory/ireneou...   \n",
       "2    https://www.hull.ac.uk/staff-directory/christo...   \n",
       "3    https://www.hull.ac.uk/staff-directory/roberto...   \n",
       "4    https://www.hull.ac.uk/staff-directory/katheri...   \n",
       "..                                                 ...   \n",
       "992  http://www.swansea.ac.uk/staff/engineering/min...   \n",
       "993  https://www.swansea.ac.uk/staff/engineering/c....   \n",
       "994  http://www.swansea.ac.uk/staff/engineering/e.s...   \n",
       "995  https://www.swansea.ac.uk/staff/engineering/a....   \n",
       "996  http://www.swansea.ac.uk/staff/engineering/z.z...   \n",
       "\n",
       "                                     research_interest   ID  \n",
       "0    \\n\\nResearch interests\\nSport rehabilitation \\...    1  \n",
       "1    \\n\\nResearch interests\\nMy areas of interests ...    2  \n",
       "2    \\n\\nPostgraduate supervision\\nDr Clarke would ...    3  \n",
       "3    \\n\\nResearch interests\\nGeomorphology \\nSedime...    4  \n",
       "4    \\n\\nResearch interests\\nPublic sector procurem...    5  \n",
       "..                                                 ...  ...  \n",
       "992  \\nAreas Of Expertise\\n\\nWave hydrodynamics\\nTw...  993  \n",
       "993                                               None  994  \n",
       "994  \\nAreas Of Expertise\\n\\nFatigue\\nCreep\\nStrain...  995  \n",
       "995  \\nAreas Of Expertise\\n\\nMechanical Design\\n3D ...  996  \n",
       "996                                               None  997  \n",
       "\n",
       "[997 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2yM7uUb3yqT"
   },
   "source": [
    "## B. Indexer\n",
    "Second part of a search engine is an indexer. It's basically a smart storage of our data in which we can later easily retrieve data given a search query.\n",
    "It parses the name and research interest of the data scraped by the crawler to single words. All these words make up the vocabulary of our index. Next step is to put the ID of the data in the posting lists of the words that the data contains. For example data called \"This happened today\" will be stored in posting lists of terms \"this\", \"happened\" and \"today\".\n",
    "Before creating the index we preprocess the text of the data in order to get rid of useless information. We the text of accents and turn everything to lowercase. Next we perform lemmatization. This is slightly smarter version of stemming. Essentially, it's a word normalization, e.g. all nouns to singular, all verbs in present tense etc.\n",
    "\n",
    "Let's do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VeVsyIKnG6hY"
   },
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "zvVE1rsxG8He",
    "outputId": "9404b419-edd3-4ff7-9b12-8c4a1485f1a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ntorj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ntorj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ntorj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ntorj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TBG-No068Cx"
   },
   "outputs": [],
   "source": [
    "single_entry = university.loc[0,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "QCSyZSzUBS9V",
    "outputId": "03a7ae52-a887-4775-abae-2f9cc4b344c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "names                                               Miss Amy Tomlinson\n",
       "link                 https://www.hull.ac.uk/staff-directory/amy-tom...\n",
       "research_interest    \\n\\nResearch interests\\nSport rehabilitation \\...\n",
       "ID                                                                   1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWfZEQpG7oEk"
   },
   "source": [
    "### Text preprocessing\n",
    "Turn title to lowercase, remove accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nP_6t0iKh84"
   },
   "outputs": [],
   "source": [
    "def process_string(text):\n",
    "  text = text.lower() #to lowercase\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation)) #strip punctuation\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "nvWZvb4s_e-L",
    "outputId": "088ca639-469d-43ae-cb17-165106a151fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nresearch interests\\nsport rehabilitation \\n \\nrecovery interventions in collision sports \\n \\nexercise rehabilitation for special populations\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_string(single_entry.research_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFXsuTQKGSU6"
   },
   "source": [
    "Now, lemmatize, i.e. word normalization.\n",
    "\n",
    "This method requires some additional information about the words. We need to find the word category of each word, e.g. verb, noun etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtWfwUq5GriG"
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_N8ZzKMLG0dV"
   },
   "source": [
    "Test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "DGxXCIneHKZ7",
    "outputId": "3b98eb1f-d833-4d45-80d0-cc017e26214d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple: n\n",
      " Run: v\n",
      " Happy: a\n"
     ]
    }
   ],
   "source": [
    "print(\"Apple: {}\\n Run: {}\\n Happy: {}\" .format(get_wordnet_pos(\"apple\"), get_wordnet_pos(\"run\"), get_wordnet_pos(\"happy\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFBmqVwOIBi_"
   },
   "source": [
    "We also need to remove stopwords, i.e. words with low informational value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKRZSEhCI_cG"
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpgU0fANJCtz"
   },
   "source": [
    "Now we'll iterate over all words in text, lemmatize and return the transformed string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0q1Vnrm0IYTp"
   },
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def stop_lemmatize(doc):\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    tmp = \"\"\n",
    "    for w in tokens:\n",
    "        if w not in stop:\n",
    "            tmp += lem.lemmatize(w, get_wordnet_pos(w)) + \" \"\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "3E0kf2AOIyZT",
    "outputId": "4c65a9fd-0114-490b-ea7e-290f440604c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Research interest Sport rehabilitation Recovery intervention collision sport Exercise rehabilitation special population '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_lemmatize(doc = single_entry.research_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HoG2PiXLzfg"
   },
   "outputs": [],
   "source": [
    "def process_string(text):\n",
    "  text = text.lower() #to lowercase\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation)) #strip punctuation\n",
    "  text = stop_lemmatize(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "iIhgs5AjMIAQ",
    "outputId": "c4528eb4-23ad-45fc-cdb1-1c25c78367b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.98 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'research interest sport rehabilitation recovery intervention collision sport exercise rehabilitation special population '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time process_string(single_entry.research_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5ONtU65MRV5"
   },
   "source": [
    "Now we apply the process_string function to all names and research interest in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wucZF2ONMYJM"
   },
   "outputs": [],
   "source": [
    "university_processed = university.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-QeP2F9NlqF"
   },
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "  df['names'] = df['names'].apply(process_string)\n",
    "  df['research_interest'] = df['research_interest'].apply(process_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "7f_GpqAHMztr",
    "outputId": "6bb851fb-da67-4e63-f70c-4e6c496e8447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.9 s\n"
     ]
    }
   ],
   "source": [
    "%time transform_df(university_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "eAs0QsWoM9IQ",
    "outputId": "242cd3fe-5cc7-45d8-a0dd-e1f274739faf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>link</th>\n",
       "      <th>research_interest</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miss amy tomlinson</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/amy-tom...</td>\n",
       "      <td>research interest sport rehabilitation recover...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dr ireneous soyiri</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/ireneou...</td>\n",
       "      <td>research interest area interest include enviro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christopher clarke</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/christo...</td>\n",
       "      <td>postgraduate supervision dr clarke would welco...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberto fernandez arrieta</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/roberto...</td>\n",
       "      <td>research interest geomorphology sediment trans...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miss katherine bloomfield</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/katheri...</td>\n",
       "      <td>research interest public sector procurement pr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        names  \\\n",
       "0         miss amy tomlinson    \n",
       "1         dr ireneous soyiri    \n",
       "2         christopher clarke    \n",
       "3  roberto fernandez arrieta    \n",
       "4  miss katherine bloomfield    \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.hull.ac.uk/staff-directory/amy-tom...   \n",
       "1  https://www.hull.ac.uk/staff-directory/ireneou...   \n",
       "2  https://www.hull.ac.uk/staff-directory/christo...   \n",
       "3  https://www.hull.ac.uk/staff-directory/roberto...   \n",
       "4  https://www.hull.ac.uk/staff-directory/katheri...   \n",
       "\n",
       "                                   research_interest  ID  \n",
       "0  research interest sport rehabilitation recover...   1  \n",
       "1  research interest area interest include enviro...   2  \n",
       "2  postgraduate supervision dr clarke would welco...   3  \n",
       "3  research interest geomorphology sediment trans...   4  \n",
       "4  research interest public sector procurement pr...   5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "university_processed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoeBvn0wPJCM"
   },
   "source": [
    "Now we can iterate over all entries to create the index. We'll go step by step again before wrapping it all in one nice function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD-MeaW2W8qC"
   },
   "source": [
    "Merge title and summary into one field and drop all columns except for ID as we don't need those anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pa8k3MXlXDcc"
   },
   "outputs": [],
   "source": [
    "university_processed['text'] = university_processed['names'] + \" \" + university_processed['research_interest']\n",
    "drop_cols = ['names', 'research_interest', 'link']\n",
    "university_processed = university_processed.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "GIoqUWscY7-J",
    "outputId": "6eb33ba1-3995-49eb-d57c-3df19e3b0990"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       int64\n",
       "text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "university_processed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N240s8Nj8mRD"
   },
   "source": [
    "Add this part to a transform_df function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jiino7VO8o7Y"
   },
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "  df = df\n",
    "  df['names'] = df['names'].apply(process_string)\n",
    "  df['research_interest'] = df['research_interest'].apply(process_string)\n",
    "  df['text'] = df['names'] + \" \" + df['research_interest']\n",
    "  drop_cols = ['names', 'research_interest', 'link']\n",
    "  df = df.drop(drop_cols, axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UMJEydsAeur"
   },
   "source": [
    "### Build index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srGNuGhDZo3b"
   },
   "source": [
    "Now we'll build index with just one entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "N8_Uw87eZtHh",
    "outputId": "0cf59a66-f2a9-45dd-8e06-bee823a59232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                                      1\n",
      "text    miss amy tomlinson  research interest sport re...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "single_entry = university_processed.loc[0,:].copy()\n",
    "print(single_entry)\n",
    "index_test = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YAzw0E4cZ5f9"
   },
   "source": [
    "Split the entry to single words and return list and save entry's ID as object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0C1n-qMUZ0_7"
   },
   "outputs": [],
   "source": [
    "words = single_entry.text.split()\n",
    "ID = single_entry.ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gO0AQCZRalH9"
   },
   "source": [
    "Each word in index' vocabulary is a dictionary key and has its own posting list with IDs. Let's construct one word vocabulary as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BHgo8mtSae96",
    "outputId": "25f4403f-f06d-4201-e91f-7640c98565dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'miss': [1]}\n"
     ]
    }
   ],
   "source": [
    "word = words[0]\n",
    "sample = {word: [ID]}\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWWaf60bbEPf"
   },
   "source": [
    "Now we iterate over all words and if they aren't in the vocabulary yet we add them. Also for each word we append the entry ID to the posting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwRfN3uObCur"
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "  if word in index_test.keys():\n",
    "    if ID not in index_test[word]:\n",
    "      index_test[word].append(ID)\n",
    "  else:\n",
    "    index_test[word] = [ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "T0wlU3SnctOf",
    "outputId": "0fd1cd94-1925-4788-fa76-645976360af7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'miss': [1], 'amy': [1], 'tomlinson': [1], 'research': [1], 'interest': [1], 'sport': [1], 'rehabilitation': [1], 'recovery': [1], 'intervention': [1], 'collision': [1], 'exercise': [1], 'special': [1], 'population': [1]}\n"
     ]
    }
   ],
   "source": [
    "print(index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJYeIbiRdU7l"
   },
   "source": [
    "Now this process can be repeated for all entries in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XO1iPcPdkRj"
   },
   "outputs": [],
   "source": [
    "def index_it(single_entry, index):\n",
    "  words = single_entry.text.split()\n",
    "  ID = single_entry.ID\n",
    "  for word in words:\n",
    "    if word in index.keys():\n",
    "      if ID not in index[word]:\n",
    "        index[word].append(ID)\n",
    "    else:\n",
    "      index[word] = [ID]\n",
    "  return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YL1z26mseByu",
    "outputId": "420f83e3-0f87-4ace-97df-b5bc29469e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'miss': [1], 'amy': [1], 'tomlinson': [1], 'research': [1], 'interest': [1], 'sport': [1], 'rehabilitation': [1], 'recovery': [1], 'intervention': [1], 'collision': [1], 'exercise': [1], 'special': [1], 'population': [1]}\n"
     ]
    }
   ],
   "source": [
    "ind = index_it(single_entry=single_entry, index= {})\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sPNcdzIZI-On"
   },
   "source": [
    "Again we can iterate over all entries in the database with scraped articles, process them append to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ju8eHusneNaD"
   },
   "outputs": [],
   "source": [
    "def index_all(df, index):\n",
    "  for i in range(len(df)):\n",
    "    single_entry = df.loc[i,:]\n",
    "    index = index_it(single_entry = single_entry, index = index)\n",
    "  return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "LgoKdHiGevlu",
    "outputId": "6298539b-cfe1-40b4-88f1-472c9bce7a37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12199"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = index_all(university_processed, index = {})\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqj9PXDtJLgG"
   },
   "source": [
    "Finally we wrap everything in one nice function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RR7asUo8BX-"
   },
   "outputs": [],
   "source": [
    "def build_index(df, index):\n",
    "    to_add = transform_df(df)\n",
    "    index = index_all(df = to_add, index = index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpZyJuBp8CyH"
   },
   "outputs": [],
   "source": [
    "idx = build_index(df = university, index = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "FoZv54Ey8slh",
    "outputId": "d447ffea-65e3-4756-bc29-60bf1f77a004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12199"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vbaEOXCAaET"
   },
   "source": [
    "It can be of course opened again with following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVI6tcJh9mzP"
   },
   "source": [
    "# Bb Ranked retrieval\n",
    "  The user would probably prefer the more relevant pages to be displayed before those that are less relevant (hopefully they're at least a bit relevant).\n",
    "For our search engine to support such option we need to store some information about the scraped documents that could be later used for this purpose.\n",
    "We'll use averaged word2vec for this purpose. Word2Vec model is single hidden-layer neural network. The hidden layer is actually what is so useful about this model. Given a word the layer's activation gives a unique vector that word. For each document we can iterate over all words, extract their vectors and then by averaging obtain a document vector. \n",
    "  Compared to other methods averaged word2vec has multiple advantages. Unlike simpler methods such as bag-of-words, n-grams and tf-idf the size of the vectors is fixed. For example bag-of-words is also using vectors but the size of these vectors equals the number of unique words in the corpus. This means that the computational and storage requirements get larger as the corpus gets larger.\n",
    "  Averaged word2vec is also able to represent the documents on more abstract level than simpler methods and should therefore provide better method of ranking.\n",
    "  We're using word2vec rather than doc2vec because we can simply use pretrained word2vec model to compute the document vectors. Using doc2vec would mean training a neural network from scratch which requires computational power, time and rather large dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aogzj51-XIr"
   },
   "source": [
    "Import and download pretrained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "TzGvdfpM9rAr",
    "outputId": "e2bf3d7e-c160-477f-dab4-f0ec31d6ab4e"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5ICnU0Q-bfo"
   },
   "source": [
    "Load word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "rYt1PwiB99RY",
    "outputId": "dfd186d1-0626-450f-bd35-dae17ad1ce33"
   },
   "outputs": [],
   "source": [
    "#DOWNLOAD PRETRAINED  NETWORK FROM https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQuWTsqA-fXc"
   },
   "source": [
    "Try getting vectors for all words in the text and averaging to get single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "cI5z0s2u-z-B",
    "outputId": "082f2316-1048-40fa-fb78-95aa5b9866b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['miss', 'amy', 'tomlinson', 'research', 'interest', 'sport', 'rehabilitation', 'recovery', 'intervention', 'collision', 'sport', 'exercise', 'rehabilitation', 'special', 'population']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIQbeAyZ-2ra"
   },
   "outputs": [],
   "source": [
    "def average_vectors(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    if len(doc) == 0:\n",
    "      return np.zeros(300)\n",
    "    else:\n",
    "      return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dbVzj05u_BBz",
    "outputId": "5e1a91a8-0eee-4c86-f1a3-3e3073a2cdc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%time test_vec = average_vectors(word2vec, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSg9chdM_sMc"
   },
   "source": [
    "Now we can iterate over documents, compute their vectors and construct a document vectors database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDajpm9W_z0b"
   },
   "outputs": [],
   "source": [
    "def prepare_ranking(df):\n",
    "  corpus = df[['ID', 'text']].copy()\n",
    "  doc_vecs = {}\n",
    "  for i in range(len(corpus)):\n",
    "    row = corpus.loc[i,:]\n",
    "    text = row.text.split()\n",
    "    doc_vecs[row.ID]=average_vectors(word2vec, text)\n",
    "  doc_vecs = pd.DataFrame.from_dict(data=doc_vecs, orient=\"index\")\n",
    "  doc_vecs['ID'] = doc_vecs.index\n",
    "  return doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdV6EV7EB0Ie"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.033639</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>-0.006880</td>\n",
       "      <td>0.080584</td>\n",
       "      <td>-0.054583</td>\n",
       "      <td>0.065465</td>\n",
       "      <td>0.137582</td>\n",
       "      <td>-0.219918</td>\n",
       "      <td>0.043688</td>\n",
       "      <td>-0.025251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012399</td>\n",
       "      <td>0.015765</td>\n",
       "      <td>-0.031241</td>\n",
       "      <td>0.071703</td>\n",
       "      <td>0.015647</td>\n",
       "      <td>-0.041532</td>\n",
       "      <td>-0.047892</td>\n",
       "      <td>-0.039115</td>\n",
       "      <td>-0.045537</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.044364</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.038593</td>\n",
       "      <td>0.064039</td>\n",
       "      <td>-0.013248</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.049146</td>\n",
       "      <td>-0.093369</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>-0.044781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027362</td>\n",
       "      <td>-0.052934</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>0.056342</td>\n",
       "      <td>-0.016182</td>\n",
       "      <td>-0.019038</td>\n",
       "      <td>0.090509</td>\n",
       "      <td>-0.001769</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.133180</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.040707</td>\n",
       "      <td>0.026464</td>\n",
       "      <td>-0.021356</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>-0.122334</td>\n",
       "      <td>0.088109</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097669</td>\n",
       "      <td>-0.025110</td>\n",
       "      <td>0.028538</td>\n",
       "      <td>-0.040394</td>\n",
       "      <td>0.059853</td>\n",
       "      <td>-0.061819</td>\n",
       "      <td>-0.095485</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.037643</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031822</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>-0.001853</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>-0.149170</td>\n",
       "      <td>0.036586</td>\n",
       "      <td>-0.028792</td>\n",
       "      <td>-0.152965</td>\n",
       "      <td>0.032604</td>\n",
       "      <td>-0.049028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002744</td>\n",
       "      <td>-0.063599</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.001653</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>-0.042178</td>\n",
       "      <td>-0.061358</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>-0.032465</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.044116</td>\n",
       "      <td>0.033764</td>\n",
       "      <td>0.019347</td>\n",
       "      <td>0.063199</td>\n",
       "      <td>-0.054460</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>0.154236</td>\n",
       "      <td>-0.076408</td>\n",
       "      <td>0.088623</td>\n",
       "      <td>-0.015291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006299</td>\n",
       "      <td>-0.071753</td>\n",
       "      <td>0.048958</td>\n",
       "      <td>0.042619</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>-0.028208</td>\n",
       "      <td>-0.094398</td>\n",
       "      <td>-0.009499</td>\n",
       "      <td>-0.017594</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>-0.032356</td>\n",
       "      <td>0.044762</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.083702</td>\n",
       "      <td>-0.119747</td>\n",
       "      <td>0.077774</td>\n",
       "      <td>-0.013001</td>\n",
       "      <td>-0.196220</td>\n",
       "      <td>0.045048</td>\n",
       "      <td>0.062546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>-0.045418</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>0.035725</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>-0.022430</td>\n",
       "      <td>-0.068256</td>\n",
       "      <td>-0.059845</td>\n",
       "      <td>0.045273</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.212280</td>\n",
       "      <td>0.095703</td>\n",
       "      <td>-0.007629</td>\n",
       "      <td>0.125153</td>\n",
       "      <td>0.100250</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>-0.016743</td>\n",
       "      <td>-0.174133</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>0.084656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140930</td>\n",
       "      <td>-0.067017</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>-0.069565</td>\n",
       "      <td>-0.088501</td>\n",
       "      <td>-0.156799</td>\n",
       "      <td>-0.173462</td>\n",
       "      <td>-0.145264</td>\n",
       "      <td>0.147766</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.002963</td>\n",
       "      <td>0.106268</td>\n",
       "      <td>-0.039706</td>\n",
       "      <td>0.095398</td>\n",
       "      <td>-0.152854</td>\n",
       "      <td>0.157559</td>\n",
       "      <td>-0.083024</td>\n",
       "      <td>-0.207053</td>\n",
       "      <td>0.112108</td>\n",
       "      <td>0.024325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087114</td>\n",
       "      <td>-0.074174</td>\n",
       "      <td>0.021534</td>\n",
       "      <td>-0.079060</td>\n",
       "      <td>-0.021340</td>\n",
       "      <td>-0.131270</td>\n",
       "      <td>-0.047857</td>\n",
       "      <td>0.063665</td>\n",
       "      <td>-0.040827</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.093140</td>\n",
       "      <td>-0.041583</td>\n",
       "      <td>0.034674</td>\n",
       "      <td>-0.023224</td>\n",
       "      <td>-0.212476</td>\n",
       "      <td>-0.002386</td>\n",
       "      <td>0.029651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130853</td>\n",
       "      <td>-0.109033</td>\n",
       "      <td>0.126782</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>-0.017285</td>\n",
       "      <td>-0.057029</td>\n",
       "      <td>-0.151337</td>\n",
       "      <td>-0.085132</td>\n",
       "      <td>-0.012524</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.179688</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.138672</td>\n",
       "      <td>0.069255</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>-0.197103</td>\n",
       "      <td>0.103923</td>\n",
       "      <td>0.089437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054118</td>\n",
       "      <td>-0.018473</td>\n",
       "      <td>0.052572</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>-0.011068</td>\n",
       "      <td>-0.179118</td>\n",
       "      <td>-0.096191</td>\n",
       "      <td>-0.070333</td>\n",
       "      <td>0.127848</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "1   -0.033639  0.064815 -0.006880  0.080584 -0.054583  0.065465  0.137582   \n",
       "2   -0.044364  0.009599  0.038593  0.064039 -0.013248  0.032375  0.049146   \n",
       "3   -0.133180  0.010523  0.040707  0.026464 -0.021356  0.057363  0.043726   \n",
       "4    0.031822  0.030651 -0.001853  0.008954 -0.149170  0.036586 -0.028792   \n",
       "5   -0.044116  0.033764  0.019347  0.063199 -0.054460 -0.001245  0.154236   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "993 -0.032356  0.044762  0.011742  0.083702 -0.119747  0.077774 -0.013001   \n",
       "994 -0.212280  0.095703 -0.007629  0.125153  0.100250  0.004333 -0.016743   \n",
       "995 -0.002963  0.106268 -0.039706  0.095398 -0.152854  0.157559 -0.083024   \n",
       "996 -0.031346  0.003174  0.009143  0.093140 -0.041583  0.034674 -0.023224   \n",
       "997 -0.179688  0.000936  0.099609  0.066162  0.138672  0.069255  0.005290   \n",
       "\n",
       "            7         8         9  ...       291       292       293  \\\n",
       "1   -0.219918  0.043688 -0.025251  ... -0.012399  0.015765 -0.031241   \n",
       "2   -0.093369  0.116338 -0.044781  ...  0.027362 -0.052934  0.024333   \n",
       "3   -0.122334  0.088109  0.002358  ...  0.097669 -0.025110  0.028538   \n",
       "4   -0.152965  0.032604 -0.049028  ... -0.002744 -0.063599 -0.001956   \n",
       "5   -0.076408  0.088623 -0.015291  ... -0.006299 -0.071753  0.048958   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "993 -0.196220  0.045048  0.062546  ...  0.045069 -0.045418  0.052832   \n",
       "994 -0.174133  0.082458  0.084656  ...  0.140930 -0.067017  0.057617   \n",
       "995 -0.207053  0.112108  0.024325  ...  0.087114 -0.074174  0.021534   \n",
       "996 -0.212476 -0.002386  0.029651  ...  0.130853 -0.109033  0.126782   \n",
       "997 -0.197103  0.103923  0.089437  ...  0.054118 -0.018473  0.052572   \n",
       "\n",
       "          294       295       296       297       298       299   ID  \n",
       "1    0.071703  0.015647 -0.041532 -0.047892 -0.039115 -0.045537    1  \n",
       "2   -0.000247  0.056342 -0.016182 -0.019038  0.090509 -0.001769    2  \n",
       "3   -0.040394  0.059853 -0.061819 -0.095485  0.004415  0.037643    3  \n",
       "4   -0.001653  0.026438 -0.042178 -0.061358  0.030640 -0.032465    4  \n",
       "5    0.042619  0.006645 -0.028208 -0.094398 -0.009499 -0.017594    5  \n",
       "..        ...       ...       ...       ...       ...       ...  ...  \n",
       "993  0.035725  0.011257 -0.022430 -0.068256 -0.059845  0.045273  993  \n",
       "994 -0.069565 -0.088501 -0.156799 -0.173462 -0.145264  0.147766  994  \n",
       "995 -0.079060 -0.021340 -0.131270 -0.047857  0.063665 -0.040827  995  \n",
       "996 -0.016748 -0.017285 -0.057029 -0.151337 -0.085132 -0.012524  996  \n",
       "997 -0.041667 -0.011068 -0.179118 -0.096191 -0.070333  0.127848  997  \n",
       "\n",
       "[997 rows x 301 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vecs = prepare_ranking(df=university)\n",
    "doc_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwLh0z5hAiGF"
   },
   "source": [
    "## C. Query processor\n",
    "The final part of a search engine is a query processor which actually performs the search task. Given a query by user the processor should return list of relevant documents.\n",
    "There are multiple types of queries. We'll start with a simple \"google-ish\" query where assume the user looks for documents relevant to all words in the query. Therefore we transform the query to boolean by connecting all words with AND operator.\n",
    "\n",
    "First, the processor preprocesses the query the same way as the indexer preprocessed the text. In other words, we normalize the query to match the format of text in the index. Next, the query is parsed to single words. We look into index if these words are part of the vocabulary. If a word is in index we retrieve its posting list. Finally, we look for intersection of all retrieved posting lists. The result is list of document IDs that the user asked for.\n",
    "However, we need to return something more useful than just a list of IDs. Therefore,we retrieve the information stored about the documents in the university database. Before printing the results we should also rank the documents. This ranking should be based on relevance to query.\n",
    "\n",
    "-----\n",
    "To implement:\n",
    " - Boolean query\n",
    " - phrase matching\n",
    " -----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyNAejSKMEyx"
   },
   "source": [
    "### Normalize query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPu2TdudD797"
   },
   "source": [
    "Let's define an example query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JUyKhZvEKjc"
   },
   "outputs": [],
   "source": [
    "test = \"Christopher Clarke\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmMKVw28EXcW"
   },
   "source": [
    "Now we use the \"process string\" function from used by indexer to normalize the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "DZKoWbSvEWnp",
    "outputId": "f76a44d5-3c55-4c2a-8949-7174094dba55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: Christopher Clarke.\n",
      "Normalized query: christopher clarke .\n"
     ]
    }
   ],
   "source": [
    "print(\"User query: {}.\" .format(test))\n",
    "test_norm = process_string(test)\n",
    "print(\"Normalized query: {}.\" .format(test_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pg4x9bo6E2Nd"
   },
   "source": [
    "Now we split the query into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNL9FbheEiSr"
   },
   "outputs": [],
   "source": [
    "test_split = test_norm.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psMVdYaeFvSr"
   },
   "source": [
    "And we wrap this in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlFn4ChDF1Mh"
   },
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "  norm = process_string(query)\n",
    "  return norm.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UX4rtmWMKLX"
   },
   "source": [
    "### Retrieve from index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3rrUZ4uFOZR"
   },
   "source": [
    "And we iterate over the words, looking if they're in the index vocabulary. If so then we retrieve the associated posting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceY2E-MzFLKT"
   },
   "outputs": [],
   "source": [
    "retrieved = []\n",
    "for word in test_split:\n",
    "  if word in index.keys():\n",
    "    retrieved.append(index[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SEe_66IHyyk"
   },
   "source": [
    "Now we look for the intersection of all posting lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0czw-uJUH2HD"
   },
   "outputs": [],
   "source": [
    "def lists_intersection(lists):\n",
    "  intersect = list(set.intersection(*map(set, lists)))\n",
    "  intersect.sort()\n",
    "  return intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ckV3JFxxHEQv",
    "outputId": "c2ef9053-2235-49bd-d514-7f9dd769c67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "result = lists_intersection(retrieved)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNF2rAIvJjkk"
   },
   "source": [
    "Let's wrap this part in a function before proceeding to formatting the results. The additional if statement is for cases when there's nothing retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CQ4fLj9JqBS"
   },
   "outputs": [],
   "source": [
    "def search_googleish(query, index=idx):\n",
    "  query_split = process_query(query)\n",
    "  retrieved = []\n",
    "  for word in query_split:\n",
    "    if word in index.keys():\n",
    "      retrieved.append(index[word])\n",
    "  if len(retrieved)>0:\n",
    "    result = lists_intersection(retrieved)\n",
    "  else:\n",
    "      result = ['No Information Found']\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "u6jorxcKK0NQ",
    "outputId": "86b19d7d-c53b-4c2d-de3d-216d72dbfed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Information Found']\n"
     ]
    }
   ],
   "source": [
    "result_IDs = search_googleish(\"virus\", index)\n",
    "print(result_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2bZhASYLQMT"
   },
   "source": [
    "-----\n",
    "\n",
    "*TO DO:\n",
    "If there's no document retrieved, try removing one term and looking for simplified query + tell user that such document doesn't include term X.*\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lu8le1C1MCWi"
   },
   "source": [
    "### Retrieve from our database\n",
    "Now we need to connect the retrieved IDs with some useful information stored in database that we first use to refine the results and then to print nice result to user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "XeNE1jlWMdsz",
    "outputId": "23149f06-9f20-4dc6-ff93-404de1380d51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>link</th>\n",
       "      <th>research_interest</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miss amy tomlinson</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/amy-tom...</td>\n",
       "      <td>research interest sport rehabilitation recover...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dr ireneous soyiri</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/ireneou...</td>\n",
       "      <td>research interest area interest include enviro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christopher clarke</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/christo...</td>\n",
       "      <td>postgraduate supervision dr clarke would welco...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberto fernandez arrieta</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/roberto...</td>\n",
       "      <td>research interest geomorphology sediment trans...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miss katherine bloomfield</td>\n",
       "      <td>https://www.hull.ac.uk/staff-directory/katheri...</td>\n",
       "      <td>research interest public sector procurement pr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        names  \\\n",
       "0         miss amy tomlinson    \n",
       "1         dr ireneous soyiri    \n",
       "2         christopher clarke    \n",
       "3  roberto fernandez arrieta    \n",
       "4  miss katherine bloomfield    \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.hull.ac.uk/staff-directory/amy-tom...   \n",
       "1  https://www.hull.ac.uk/staff-directory/ireneou...   \n",
       "2  https://www.hull.ac.uk/staff-directory/christo...   \n",
       "3  https://www.hull.ac.uk/staff-directory/roberto...   \n",
       "4  https://www.hull.ac.uk/staff-directory/katheri...   \n",
       "\n",
       "                                   research_interest  ID  \n",
       "0  research interest sport rehabilitation recover...   1  \n",
       "1  research interest area interest include enviro...   2  \n",
       "2  postgraduate supervision dr clarke would welco...   3  \n",
       "3  research interest geomorphology sediment trans...   4  \n",
       "4  research interest public sector procurement pr...   5  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#this is our database\n",
    "meta = university.drop(['text'], axis=1).copy()\n",
    "meta.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C8jU3h7Nf3L"
   },
   "source": [
    "Query from database to get only rows of retrieved IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EkZiljCvQDdY"
   },
   "outputs": [],
   "source": [
    "def connect_id_df(retrieved_id, df):\n",
    "    return df[df.ID.isin(retrieved_id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "rAAm0Nc-M5Bh",
    "outputId": "a3bc836d-d5b2-465d-a88c-b560055db804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>link</th>\n",
       "      <th>research_interest</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [names, link, research_interest, ID]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_meta = connect_id_df(result_IDs, meta)\n",
    "result_meta.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twSUGf8jMahf"
   },
   "source": [
    "### Ranked retrieval\n",
    "Now we return back to the word2vec vectors we computed after indexing the documents.\n",
    "We'l compute the vector for the query as well and then using a cosine similarity compare query to retrieved document relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_LQ_hgGiM5ru"
   },
   "source": [
    "Compute vector for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-zOxFRfX5j3"
   },
   "outputs": [],
   "source": [
    "query_vec = average_vectors(word2vec, test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK6PYd3_PyOW"
   },
   "source": [
    "Retrieve vectors of retrieve documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-EA-K5_LKxP"
   },
   "outputs": [],
   "source": [
    "result_vecs = connect_id_df(result_IDs, doc_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZNPFm1iLtoo"
   },
   "source": [
    "Compute cosine similarity between retrieved documents and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xBh7uO3Ppu0"
   },
   "outputs": [],
   "source": [
    "def cos_similarity(a, b):\n",
    "  dot = np.dot(a, b)\n",
    "  norma = np.linalg.norm(a)\n",
    "  normb = np.linalg.norm(b)\n",
    "  cos = dot / (norma * normb)\n",
    "  return(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUzOWptuNOR9"
   },
   "outputs": [],
   "source": [
    "cos_sim = []\n",
    "for i in range(len(result_vecs)):\n",
    "  doc_vec = result_vecs.loc[i,:].drop(['ID'])\n",
    "  cos_sim.append(cos_similarity(doc_vec, query_vec))\n",
    "result_meta['rank'] = cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oyuxNuTOTsw"
   },
   "source": [
    "Sort retrieved docs by cosine similarity which is proxi for relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "DrdUUDdLMWax",
    "outputId": "86a875ea-1cc9-4e94-927c-17b4e4f5a1be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>link</th>\n",
       "      <th>research_interest</th>\n",
       "      <th>ID</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [names, link, research_interest, ID, rank]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_meta.sort_values('rank', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_A0UidLgO4L4"
   },
   "source": [
    "Wrap this in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wo8zJsy4N-i9"
   },
   "outputs": [],
   "source": [
    "def rank_results(query, results):\n",
    "  query_norm = process_query(query)\n",
    "  query_vec = average_vectors(word2vec, query_norm)\n",
    "  result_vecs = connect_id_df(results.ID, doc_vecs)\n",
    "  cos_sim = []\n",
    "  for i in range(len(result_vecs)):\n",
    "    doc_vec = result_vecs.loc[i,:].drop(['ID'])\n",
    "    cos_sim.append(cos_similarity(doc_vec, query_vec))\n",
    "  results['rank'] = cos_sim\n",
    "  results = results.sort_values('rank', axis=0)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTEOQ9pGQsbB"
   },
   "outputs": [],
   "source": [
    "final_result = rank_results(\"Christopher Clarke\", result_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsqjtFGcRf4j"
   },
   "source": [
    "### Print results to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOz-Re8pQ0Eg"
   },
   "outputs": [],
   "source": [
    "def print_results(result_df):\n",
    "  for i in range(len(result_df)):\n",
    "    res = result_df.loc[i, :]\n",
    "    print(res.names)\n",
    "    print(res.research_interest)\n",
    "    if i == len(result_df):\n",
    "        print(res.link)\n",
    "    else:\n",
    "        print(\"{}\\n\" .format(res.link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "0yY8sTZ-SEFb",
    "outputId": "09c3230c-5055-45c3-dee7-6f2774e9952a"
   },
   "outputs": [],
   "source": [
    "print_results(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXZadNiKUIGK"
   },
   "source": [
    "### Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdm4KHFsUKGG"
   },
   "outputs": [],
   "source": [
    "def search(query, dat=None):\n",
    "  result = search_googleish(query)\n",
    "  result = connect_id_df(result, meta)\n",
    "  result = rank_results(query, result)\n",
    "  print_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "0yVCIapYUMpJ",
    "outputId": "d2d6fcb7-4c91-46a2-cfc9-00cc2e214c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for:machine learning\n",
      "dr evdokia tapoglou \n",
      "research interest machine learn optimization wave forecasting offshore renewable energy climate change adaptation mitigation groundwater model \n",
      "https://www.hull.ac.uk/staff-directory/evdokia-tapoglou\n",
      "\n",
      "dr igor menezes \n",
      "research interest organisational psychology microbehaviours cognitive analytics machine learn psychometrics quantitative method psychological network personality postgraduate supervision organisational climate organisational commitment engagement organisational citizenship behaviour turnover intention reason \n",
      "https://www.hull.ac.uk/staff-directory/igor-menezes\n",
      "\n",
      "dr muhammad awais \n",
      "research interest apply ai machine learn deep learn internet thing smart city healthcare industry ict base assistive technology health biomedical signal processing wearable compute data analytics data mining \n",
      "https://www.hull.ac.uk/staff-directory/muhammad-awais\n",
      "\n",
      "dr john atanbori \n",
      "research interest computer vision machine learn deep learn application computer vision machine deep learn plant phenotyping agric technology animal behaviour \n",
      "https://www.hull.ac.uk/staff-directory/john-atanbori\n",
      "\n",
      "dr tjeerd jellema \n",
      "postgraduate supervision tjeerd welcome application area social cognition complete current phd postdoc first supervisor joana lopez pigui brain predictive machine eeg study fund university hullwhite rise sylwia macinska cognition emotion intertwine distinct ability fund university hull eszter somos exceptional autobiographical memory fund university hull cosupervisor g mazzoni richard carvey rapid detection human facial attractiveness group 2017 fund university hull cosupervisor ch liu manon krol understand others action eeg study combine tm 2017 fund university hull currently postdoc radbout university nijmegen donders institute nl martha del rosario peña sarmiento mechanism underpin mere exposure effect 2017 fund universidad de los andes colombia hull university cosupervisor j e cruz currently lecturer fundación universitaria konrad lorenz colombia dan walter understand others action theoretical approach 2016 fund 80th anniversary university hull cosupervisor burwood joanna wincenciak perception facial trustworthiness emotional action 2015 fund 80th anniversary university hull cosupervisor n e barraclough currently lecturer glasgow university letizia palumbo beyond face value involuntary emotional anticipation typical development aspergers syndrome 2015 fund 80th anniversary university hull currently senior lecturer liverpool hope university hollie burnett reconceptualisation autism spectrum disorder 2010 fund ahrcesf eurocores currently clinical psychologist retreat york tanja nijboer emotion consciousness implicit social learn postdoc fund rubiconnwo currently associate professor utrecht university matthew hudson role social cue automatic attribution intentionality fund university hull currently lecturer national college ireland jeannette lorteije real imply motion processing 2006 fund helmholtz research institute nl cosupervisor r j van wezel currently assistant professor university amsterdam \n",
      "https://www.hull.ac.uk/staff-directory/tjeerd-jellema\n",
      "\n",
      "dr darryl davis \n",
      "research interest artificial intelligence cognitive science computational creativity data mining machine learn robotics postgraduate supervision artificial intelligence computational creativity data mining machine learn robotics \n",
      "https://www.hull.ac.uk/staff-directory/darryl-davis\n",
      "\n",
      "dr ming hou \n",
      "research interest control theory application include model dynamic system signal processing estimator filter biomedical engineering application postgraduate supervision dr hou welcome application model control dynamic system biomechanics application human posture control machine learn nonlinear phenomenon pattern recognition complete phd lam cheah amartya ganguly goran mohammed \n",
      "https://www.hull.ac.uk/staff-directory/ming-hou\n",
      "\n",
      "dr yongqiang cheng \n",
      "research interest digital healthcare robotics ai embed system wsn networking data science postgraduate supervision dr chgeng welcome phd application digital healthcare machine learn roboticsflying robot ai embed system wsn data science \n",
      "https://www.hull.ac.uk/staff-directory/yongqiang-cheng\n",
      "\n",
      "dr kevin pimbblet \n",
      "research interest primary area galaxy evolution formation environment cosmologically significant timescales stellar population inside galaxy response physical environment cluster superclusters galaxy kinematics constituent growth star formation galaxy active galactic nucleus brightest cluster galaxy cd galaxy dwarf galaxy filament galaxy stretch galaxy cluster void largescale structure topology large widefield deep redshift survey sky area astronomical image processing automate classification machine learn virtual observatory catalogue match handle astrophysics physic education dark energy standard model cosmology random number generation statistic statistical method game theory postgraduate supervision observational astronomy astrophysics particular focus galaxy galaxy evolution galaxy formation stellar population galaxy agn galaxy cluster largescale structure universe complete phd charlotte wilkinson 20152019 yjan gordon 20152018 amelia frasermckelvie 20132017 jacob crossett 20122017 dane kleiner 20122017 nic bonne 20112015 david palamara 20102015 tim dolley 20102015 richard beare 20102014 brendan griffen 20082009 russell jurek 20052009 peter firth 20052008 isaac roseboom 20042007 current phd supervision mikkel kristensen mikkel lindholmer lawrence bilton oliver bartlett \n",
      "https://www.hull.ac.uk/staff-directory/kevin-pimbblet\n",
      "\n",
      "dr alastair ward \n",
      "research interest problem people wild animal bring best manage problem wildlife people bring best manage reconcile compete objective wildlife across fragment multiowner landscape measurement wildlife need take order make evidencebased decision management good estimate good need sort multidisciplinary question keep awake would like research solution people ’ problem associate wildlife especially deer also vertebrate benefit people wildlife ’ welcome chat postgraduate supervision welcome application msc research phd study wildlife management conservation mammal ecology aeroecology wildlife disease ecology complete research supervision petrovan 2012 landscape ecology brown hare european rabbit pasture north east england university hull palmer g 2014 deer britain population spread implication biodiversity whitehead trust lush l 2015 functional ecology interaction wild domestic herbivore university hull oneill h 2016 deer biodiversity management ecotourism hebrides conflict mutual benefit nerc fera matos c 2018 pondbreeding amphibian connectivity tunnel maintain triturus cristatus movement use road mitigation natural england university hull logan 2019 ecology management deer thorne moor selffunded msc research current research project supervision wade role wild bird emergence avian influenza poultry farm phd payne w wader feed ecology phd hartley machine learn interrogation bird radar data phd stone pink foot goose ecology relation wind farm \n",
      "https://www.hull.ac.uk/staff-directory/alastair-ward\n",
      "\n",
      "dr xinhui \n",
      "research interest digital healthcare medical image analysis data science machine learn computer vision computer graphic virtual reality augment reality cadcam finite element analysis postgraduate supervision dr welcome application virtual reality augment reality computer vision medical image analysis data science machine learn etc \n",
      "https://www.hull.ac.uk/staff-directory/xinhui-ma\n",
      "\n",
      "dr georgios efthimiou \n",
      "research interest microbial biofilms gut microbiome microbial product microbial community probiotic natural antimicrobial project funder grant start status project thyme machine learn metabolic model key bacteria grow biofilm mode human gut funder research england grant £500000 start 1 august 2019 status ongoing project summer internship funder 00 100 di 0 overhead 0 inflation charity grant £600000 start 15 june 2020 status ongoing postgraduate supervision microbial biofilms probiotic natural antimicrobial microbial community infection immunity \n",
      "https://www.hull.ac.uk/staff-directory/georgios-efthimiou\n",
      "\n",
      "professor vasilis argyriou \n",
      "research project £225000 5grit 2018 5g rural integrate testbed innovate uk project provide partner company chance test application manage network environment real people testbed consists quickline broadway wireless network lead isps trial manage cybermoor lead social enterprise use case developer provide unmanned aerial system uass collect video data livestock movement analyse kingston university ku precision farm new rural broadband delivery augment reality tourist lay foundation organisation trial innovative application technology testbed future year €102800 g5437 witness 2018 wide integration sensor network enable smart surveillance nato witness proposes innovative framework situational awareness decision make improve effectiveness security force prevent deal urban attack project collaboration partner republic moldova italy work focus computer vision task related scene analysis understand application ar €106400 g5381 midas 2018 control team miniuavs support counterterrorism mission nato nato fund project start january 2018 focus counterterrorism scenario use control system miniuavs machine learn computer vision solution £150000 knowledge transfer partnership 2017 ref ktp010695 kingston university high education corporation vca technology limited ktp project start 2017 vca technology limited two year focus pedestrian counting simulation system security market analytics computer vision machine learn technique base deep learn developed evaluate project €908000 h2020iot012016 management networked iot wearable large scale demonstration cultural security application monica soundcity project monica aim provide large scale demonstration multiple exist new internet thing technology smarter living solution deployed 6 major city europe monica demonstrates large scale iot ecosystem us innovative wearable portable iot sensor actuator closedloop backend service integrate interoperable cloudbased platform capable offering multitude simultaneous target application €121739 project call thales 2014 automatic detection model 2d 3d change urban environment multi modal multitemporal remote sense data urbanmonitor project focus understand model dynamic 3d urban scene largescale many military engineering civilian application urban rural planning mapping update geographic information system surveillance transportation archeology architecture augment reality 3d visualization virtual tourism etc £64000 leidenconicyt 2014 interaction 3d virtual world use kinect entertainment development principal aim project design development novel architectural framework create new software use natural interface use bare hand solve problematic issue area like design user friendly interface able operate 3d use finger track gesture identification multi camera information fusion £62000 phd scholarship 2013 advanced natural fiber composite biomedical application project focus advanced finite element analysis predict impact damage behaviour fracture hip project 3d reconstruction use obtain hip bone structure effect low velocity impact hip fracture age people investigate supervision ra current rob dupre crowd analysis abnormal behavior detection 20172020 bappaditya mandal human detection counting 20172018 hajar sadeghi sokeh group behaviour analysis retrieval 20172020 phd current yutthana pirunsarn personalitybased machine learn improve player engagement serious game october 2017 mike daves human eye simulation vr ar application october 2017 jiri fajtl digital memory elder people dementia patient march 2017 alexandros makrodimitris advanced method generate personalize game use learn technique march 2017 kejian liu animate realistic human action behaviour game movie october 2016 anish khadka ray trace technique real time render 3d scene analysis october 2016 phd complete juan fernandez montenegro virtual reality computer vision alzheimers diagnosis october 2014 write dimitrios konstantinidis building change detection satellite image october 2014 collaboration certh rob dupre advanced 3d segmentation technique augment reality game virtual environment october 2013 victoria bloom action recognition computer game august 2011 raúl antonio herreraacuña interaction 3d virtual world use kinect february 2011 omid razmkhah prediction impact response crack human bone structure february 2011 master research complete konrad jablonski crowd behaviour analysis simulation game october 2013 matthaios doulgerakiskontoudis vision base medical feature diagnosis treatment august 2015 research student supervision main supervision mr alexandros makrodimitris supervision mr gordon johnson mr kejian liu publication \n",
      "https://www.kingston.ac.uk/staff/profile/professor-vasilis-argyriou-332/\n",
      "\n",
      "professor jeanchristophe nebel \n",
      "lead research pattern recognition machine learn apply computer vision bioinformatics support multidisciplinary international collaboration computer vision focus design machine learn approach recognise human action video data particular pioneer international collaborator usage common sense reason enhance computer visionbased action recognition feature communication acm december 2014 currently develop new genomicsinspired paradigm computer vision lead best paper prize award evostar conference bioinformatics research activity span across different aspect include protein interaction structure prediction include usage formal grammar model 3d structure protein recently lead development novel approach 3d structure prediction single chain complexed protein research apply protein involve medical condition collaboration life scientist qualification expertise phd computer science area specialism machine learn pattern recognition computer vision bioinformatics research student supervision main supervision mr aaron caffrey mr ioannis kazantzidis mr matthias pilz supervision miss amena lloyd mr stenford ruvinga publication \n",
      "https://www.kingston.ac.uk/staff/profile/professor-jean-christophe-nebel-43/\n",
      "\n",
      "dr xianzhi zhang \n",
      "manufacturing informatics big data machine learn manufacturing system integration interoperability knowledge management manufacturing digital twin cyberphysical system cnc stepnc capp publication \n",
      "https://www.kingston.ac.uk/staff/profile/dr-xianzhi-zhang-401/\n",
      "\n",
      "dr cinzia giannetti \n",
      "area expertise manufacturing system engineering big data manufacturing informatics iots machine learningdeep learn artificial intelligence process optimisation \n",
      "https://www.swansea.ac.uk/staff/engineering/c.giannetti/\n",
      "\n",
      "dr rajesh ransing \n",
      "area expertise manufacturing analytics process optimisation machine learn uncertainty quantification risk base think fmeas organisational knowledge management gait analysis bipedal walk fluid flow nanoscale computational engineering \n",
      "http://www.swansea.ac.uk/staff/engineering/r.s.ransing/\n",
      "\n",
      "dr pavel loskot \n",
      "area expertise statistical signal processing machine learn telecommunication protocol 4g5g iot compute cloud distribute edge computational molecular biology \n",
      "http://www.swansea.ac.uk/staff/engineering/p.loskot/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Search for:\")\n",
    "search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Code explanation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
